# Configuration de l'IA Locale pour AutoCut

## üìã Vue d'ensemble

AutoCut a √©t√© simplifi√© et utilise maintenant une IA locale pour g√©n√©rer des titres YouTube optimis√©s. Cette version ne n√©cessite plus OpenAI API et fonctionne enti√®rement en local.

## ‚ú® Nouvelles fonctionnalit√©s

- ‚úÖ **Mode local uniquement** : Plus besoin de choisir entre local et IA
- ‚úÖ **D√©tection am√©lior√©e des "euh"** : Patterns plus robustes et complets
- ‚úÖ **Copier-coller du texte** : Bouton pour copier directement la transcription
- ‚úÖ **G√©n√©ration de 3 titres YouTube** : IA locale pour A/B testing
- ‚ùå **Supprim√©** : Cr√©ation de shorts, sous-titres, post-traitement OpenAI

## üöÄ Installation de l'IA Locale (Ollama)

### Option 1 : Avec Ollama (Recommand√©)

Pour b√©n√©ficier de la g√©n√©ration de titres intelligente :

1. **Installer Ollama** :
   ```bash
   # Linux
   curl -fsSL https://ollama.com/install.sh | sh

   # macOS
   brew install ollama

   # Ou t√©l√©charger depuis https://ollama.com/download
   ```

2. **D√©marrer Ollama** :
   ```bash
   ollama serve
   ```

3. **T√©l√©charger un mod√®le** (recommand√© : llama2 ou mistral) :
   ```bash
   # Mod√®le recommand√© pour la g√©n√©ration de titres
   ollama pull llama2

   # Alternative plus performante (requiert plus de RAM)
   ollama pull mistral
   ```

4. **V√©rifier que √ßa fonctionne** :
   ```bash
   curl http://localhost:11434/api/tags
   ```

### Option 2 : Sans Ollama (Mode Fallback)

Si vous ne souhaitez pas installer Ollama, AutoCut fonctionnera quand m√™me avec un syst√®me de g√©n√©ration de titres simple bas√© sur des r√®gles.

## üìù Utilisation

### 1. Traiter une vid√©o

1. Uploadez votre vid√©o (MP4 ou MOV)
2. Ajustez les param√®tres de d√©tection des silences et des "euh"
3. Activez la d√©tection des h√©sitations (activ√©e par d√©faut)
4. Lancez le traitement

### 2. Copier la transcription

Une fois le traitement termin√©, cliquez sur le bouton **"üìã Copier le texte"** pour copier la transcription compl√®te dans votre presse-papier.

### 3. G√©n√©rer des titres YouTube

1. Apr√®s le traitement, cliquez sur **"‚ú® G√©n√©rer 3 Titres Optimis√©s"**
2. L'IA locale g√©n√©rera 3 titres diff√©rents :
   - **Titre 1** : √âmotionnel et accrocheur
   - **Titre 2** : Informatif et direct
   - **Titre 3** : Intrigant avec question
3. Copiez le titre de votre choix avec le bouton **"üìã Copier"**

## ‚öôÔ∏è Configuration Ollama (Optionnel)

### Changer le mod√®le par d√©faut

√âditez `/home/user/AutoCut/backend/services/ai_services/local_title_generator.py` :

```python
# Ligne 14 - Changer le mod√®le
def __init__(
    self,
    ollama_url: str = "http://localhost:11434",
    model: str = "mistral"  # Changez ici : llama2, mistral, etc.
):
```

### Mod√®les recommand√©s pour la g√©n√©ration de titres

| Mod√®le | Taille | Qualit√© | RAM requise |
|--------|--------|---------|-------------|
| `llama2` | 3.8GB | Bonne | 8GB |
| `mistral` | 4.1GB | Excellente | 8GB |
| `llama2:13b` | 7.4GB | Tr√®s bonne | 16GB |
| `mixtral` | 26GB | Excellente | 32GB |

## üîß D√©pannage

### Ollama n'est pas d√©tect√©

```bash
# V√©rifiez que Ollama est en cours d'ex√©cution
ps aux | grep ollama

# Red√©marrez Ollama
killall ollama
ollama serve
```

### G√©n√©ration de titres lente

- Utilisez un mod√®le plus petit (llama2 au lieu de mixtral)
- V√©rifiez que vous avez assez de RAM
- Fermez les autres applications gourmandes en ressources

### Les titres sont en anglais

Modifiez le prompt dans `local_title_generator.py` pour forcer le fran√ßais :

```python
# Ligne 130 environ
prompt = f"""Tu es un expert en optimisation de titres YouTube FRAN√áAIS.
IMPORTANT : R√©ponds UNIQUEMENT en fran√ßais.
...
```

## üìä Am√©lioration de la D√©tection des "Euh"

La nouvelle version d√©tecte maintenant :
- ‚úÖ Variations de "euh" : euh, heu, euuh, heuuh, etc.
- ‚úÖ "Ah" et "Oh" d'h√©sitation
- ‚úÖ "Hum", "hmm", "mmmh"
- ‚úÖ Fillers fran√ßais : "ben", "bah", "bof", "en fait", "du coup", "genre"
- ‚úÖ R√©p√©titions : "je je", "le le"
- ‚úÖ Sons de respiration d√©tect√©s par Whisper

## üìà Comparaison Avant/Apr√®s

### Avant
- 2441 lignes de code frontend
- Choix complexe local/GPT-4
- Multiples fonctionnalit√©s (shorts, sous-titres, etc.)
- D√©pendance √† OpenAI API ($$$)

### Apr√®s
- 1288 lignes de code frontend (-47%)
- Mode local uniquement
- Focus sur l'essentiel : silences + h√©sitations
- IA locale gratuite avec Ollama

## üéØ Workflow Optimis√©

1. **Upload** ‚Üí Vid√©o MP4/MOV
2. **Traitement** ‚Üí D√©tection silences + "euh" am√©lior√©e
3. **Copie** ‚Üí Bouton copier la transcription
4. **Titres** ‚Üí G√©n√©ration 3 titres optimis√©s (A/B testing)
5. **Export** ‚Üí Vid√©o + XML (Premiere/Final Cut)

## üÜò Support

Pour toute question ou probl√®me :
1. V√©rifiez que Ollama est bien install√© et en cours d'ex√©cution
2. Consultez les logs du backend : `/home/user/AutoCut/backend/logs/`
3. Mode fallback activ√© automatiquement si Ollama n'est pas disponible

## üîÑ Prochaines am√©liorations possibles

- [ ] Support de plus de mod√®les locaux (GPT4All, LlamaCpp, etc.)
- [ ] G√©n√©ration de descriptions YouTube
- [ ] G√©n√©ration de hashtags optimis√©s
- [ ] Export direct vers YouTube API
